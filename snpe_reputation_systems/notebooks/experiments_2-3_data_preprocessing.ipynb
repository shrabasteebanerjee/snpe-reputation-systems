{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86e66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import data\n",
    "with open(\"BigSim.pkl\", \"rb\") as file:\n",
    "    full_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa4985",
   "metadata": {},
   "source": [
    "### A. Prepare training data for  inference model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e307ae",
   "metadata": {},
   "source": [
    "Use 20 marketplaces to train the inference model. Considering 1600 time series per marketplace, that equals 32.000 review time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15bc62de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the full set of review time series: (32, 1600)\n",
      "Shape of the defined train set of review time series: (20, 1600)\n"
     ]
    }
   ],
   "source": [
    "# Shape the training set for the inference model: Review time series\n",
    "\n",
    "simulations = full_data[\"simulations\"]\n",
    "print(f\"Shape of the full set of review time series: {simulations.shape}\")\n",
    "\n",
    "train_simulations = simulations[:20]\n",
    "print(f\"Shape of the defined train set of review time series: {train_simulations.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a2147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the full set of parameter rho: (10, 51200, 2)\n",
      "Shape of the full set of parameter h_p: (10, 51200)\n",
      "Shape of the full set of parameter p_5: (10, 51200)\n",
      "Shape of the full set of parameter p_4: (10, 51200)\n",
      "Shape of the full set of parameter p_2: (10, 51200)\n",
      "Shape of the full set of parameter p_1: (10, 51200)\n",
      "Shape of the full set of parameter bias_5_star: (10, 51200)\n",
      "######################\n",
      "Shape of the train set of parameter rho: (10, 32000, 2)\n",
      "Shape of the train set of parameter h_p: (10, 32000)\n",
      "Shape of the train set of parameter p_5: (10, 32000)\n",
      "Shape of the train set of parameter p_4: (10, 32000)\n",
      "Shape of the train set of parameter p_2: (10, 32000)\n",
      "Shape of the train set of parameter p_1: (10, 32000)\n",
      "Shape of the train set of parameter bias_5_star: (10, 32000)\n"
     ]
    }
   ],
   "source": [
    "# Shape the training set for the inference model: Simulation parameters\n",
    "\n",
    "parameters = full_data[\"simulation_parameters\"]\n",
    "for key, value in parameters.items():\n",
    "    print(f\"Shape of the full set of parameter {key}: {value.shape}\")\n",
    "print(\"######################\")\n",
    "\n",
    "train_parameters = {}  \n",
    "\n",
    "for key, value in parameters.items():\n",
    "    if key == \"rho\":\n",
    "        train_parameters[key] = value[:, :32000, :]\n",
    "    else:\n",
    "        train_parameters[key] = value[:, :32000]\n",
    "\n",
    "for key, value in train_parameters.items():\n",
    "    print(f\"Shape of the train set of parameter {key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcba2052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute train_simulations and train_parameters in a copy of the simulation to create the train simulation (train_data)\n",
    "\n",
    "train_data = full_data.copy()\n",
    "train_data[\"simulations\"] = train_simulations\n",
    "train_data[\"simulation_parameters\"] = train_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92a21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store training data as .pkl\n",
    "\n",
    "with open('training_simulation_data.pkl', 'wb') as file:\n",
    "    pickle.dump(train_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcc432",
   "metadata": {},
   "source": [
    "### B. Prepare experiments' data (\"Base group\")\n",
    "\n",
    "All simulated time series not used to train the inference model (12/32 marketplaces - 19200 time series) will be used to build the \"treatment\" groups (See C. and D. below) and for conditional sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4999da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the full set of review time series: (32, 1600)\n",
      "Shape of the defined experimental set of review time series: (12, 1600)\n"
     ]
    }
   ],
   "source": [
    "# Shape experiments' data: time series\n",
    "\n",
    "simulations = full_data[\"simulations\"]\n",
    "print(f\"Shape of the full set of review time series: {simulations.shape}\")\n",
    "\n",
    "experiment_simulations = simulations[20:]\n",
    "print(f\"Shape of the defined experimental set of review time series: {experiment_simulations.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e18143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the full set of parameter rho: (10, 51200, 2)\n",
      "Shape of the full set of parameter h_p: (10, 51200)\n",
      "Shape of the full set of parameter p_5: (10, 51200)\n",
      "Shape of the full set of parameter p_4: (10, 51200)\n",
      "Shape of the full set of parameter p_2: (10, 51200)\n",
      "Shape of the full set of parameter p_1: (10, 51200)\n",
      "Shape of the full set of parameter bias_5_star: (10, 51200)\n",
      "######################\n",
      "Shape of the experiment set of parameter rho: (10, 19200, 2)\n",
      "Shape of the experiment set of parameter h_p: (10, 19200)\n",
      "Shape of the experiment set of parameter p_5: (10, 19200)\n",
      "Shape of the experiment set of parameter p_4: (10, 19200)\n",
      "Shape of the experiment set of parameter p_2: (10, 19200)\n",
      "Shape of the experiment set of parameter p_1: (10, 19200)\n",
      "Shape of the experiment set of parameter bias_5_star: (10, 19200)\n"
     ]
    }
   ],
   "source": [
    "# Shape experiments' data: simulation parameters\n",
    "\n",
    "parameters = full_data[\"simulation_parameters\"]\n",
    "for key, value in parameters.items():\n",
    "    print(f\"Shape of the full set of parameter {key}: {value.shape}\")\n",
    "print(\"######################\")\n",
    "\n",
    "experiment_parameters = {}  \n",
    "\n",
    "for key, value in parameters.items():\n",
    "    if key == \"rho\":\n",
    "        experiment_parameters[key] = value[:, 32000:, :]\n",
    "    else:\n",
    "        experiment_parameters[key] = value[:, 32000:]\n",
    "\n",
    "for key, value in experiment_parameters.items():\n",
    "    print(f\"Shape of the experiment set of parameter {key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f9d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute experiment_simulations and experiment_parameters in a copy of the simulation to create the train simulation (train_data)\n",
    "\n",
    "experiment_data = full_data.copy()\n",
    "experiment_data[\"simulations\"] = experiment_simulations\n",
    "experiment_data[\"simulation_parameters\"] = experiment_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92c7a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store base experiment data as .pkl\n",
    "\n",
    "with open('inference_experiment_base_data.pkl', 'wb') as file:\n",
    "    pickle.dump(experiment_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc56c7",
   "metadata": {},
   "source": [
    "### C. Preparation for inference experiment 1: Jumble review time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420c0ad",
   "metadata": {},
   "source": [
    "From the base group, modify the order in which reviews are left by simulated users in all time series while preserving the final review histogram shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b0c7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_1_data = experiment_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df4cf288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alternative_timeseries(final_state):\n",
    "    '''\n",
    "    Given a review timeseries' final state (histogram), returns an alternative \n",
    "    time series between the initial state ([1, 1, 1, 1, 1]) and the final state\n",
    "    generated at random.\n",
    "    '''\n",
    "    \n",
    "    # \"Total distance\": number of reviews posted for the considered product (time series length)\n",
    "    total_distance = final_state - np.ones(5)\n",
    "    \n",
    "    # If time series is empty, return itself\n",
    "    if sum(total_distance) == 0:\n",
    "        return(np.ones(5))\n",
    "    \n",
    "    # Remaining distance: number of reviews yet to be posted\n",
    "    remaining_distance = total_distance\n",
    "    \n",
    "    # New (alternative) time series\n",
    "    path = [np.array([1,1,1,1,1])]\n",
    "    \n",
    "    # Iterate over total length of time series\n",
    "    for i in range (int(sum(total_distance))):\n",
    "        \n",
    "        # Rating axes along which \"steps\" can be made\n",
    "        axes = np.where(remaining_distance)[0] \n",
    "        \n",
    "        # New rating to be added (at random)\n",
    "        new_rating_index = np.random.choice(axes)\n",
    "        \n",
    "        # Generate new rating\n",
    "        new_rating_step = np.zeros(5)\n",
    "        new_rating_step[new_rating_index] = 1\n",
    "        \n",
    "        # Update time series with new rating\n",
    "        path.append(path[-1] + new_rating_step)\n",
    "        \n",
    "        # Update \"remaining distance\" after the addtion of the last rating\n",
    "        remaining_distance = remaining_distance - new_rating_step\n",
    "        \n",
    "    # Return new alternative time series    \n",
    "    return np.array(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf9284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jumbled_timeseries = np.empty((12, 1600), dtype=object)\n",
    "\n",
    "# Loop over dimension 1 of simulated review timeseries (Marketplaces)\n",
    "for i in range(experiment_1_data[\"simulations\"].shape[0]):\n",
    "    \n",
    "    # Loop over dimension 2 of simulated review timeseries (Products)\n",
    "    for e in range(experiment_1_data[\"simulations\"].shape[1]):\n",
    "        \n",
    "        # \"Select\" original time series for the simulation\n",
    "        series = experiment_1_data[\"simulations\"][i][e]\n",
    "        \n",
    "        # Store jumbled version of the original time series in the same position of the empty array\n",
    "        jumbled_timeseries[i][e] = generate_alternative_timeseries(series[-1])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25c8747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of array of jumbled time series: (12, 1600)\n",
      "Shape of array of original simulation time series: (12, 1600)\n"
     ]
    }
   ],
   "source": [
    "# Shape sanity check\n",
    "\n",
    "print(f\"Shape of array of jumbled time series: {jumbled_timeseries.shape}\")\n",
    "\n",
    "print(f\"Shape of array of original simulation time series: {experiment_1_data['simulations'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8357c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute original simulation time series with jumbled time series\n",
    "\n",
    "experiment_1_data[\"simulations\"] = jumbled_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5955346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store experiment 1 data as .pkl\n",
    "\n",
    "with open('inference_experiment_1_data.pkl', 'wb') as file:\n",
    "    pickle.dump(experiment_1_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ccb35c",
   "metadata": {},
   "source": [
    "### D. Preparation for inference experiment 2: Increase number of reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127277a6",
   "metadata": {},
   "source": [
    "From the base group, increase the number of reviews in all time series by a factor of two while preserving the final review histogram shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "613eb491",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_2_data = experiment_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a337c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_series = experiment_2_data[\"simulations\"][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46082ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_timeseries(time_series):\n",
    "\n",
    "    # Transform time series to first differences\n",
    "    first_differences = [time_series[i] - time_series[i - 1] for i in range(1, len(time_series))]\n",
    "    \n",
    "    # Prepare \"Augmentation\" by stacking two time series' first differences\n",
    "    first_differences_double = first_differences + first_differences\n",
    "    \n",
    "    # Set initial value of new augmented time series\n",
    "    initial_value = np.array([1, 1, 1, 1, 1])\n",
    "    absolute_values = [initial_value]\n",
    "    \n",
    "    # Transform stacked first differences into absolute values\n",
    "    for diff in first_differences_double:\n",
    "        absolute_values.append(absolute_values[-1] + diff)\n",
    "        \n",
    "    absolute_values.append(absolute_values[-1] + np.ones(5))\n",
    "\n",
    "    absolute_values = np.array(absolute_values)\n",
    "    \n",
    "    return(absolute_values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "607f90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_timeseries = np.empty((12, 1600), dtype=object)\n",
    "\n",
    "# Loop over dimension 1 of simulated review timeseries (Marketplaces)\n",
    "for i in range(experiment_2_data[\"simulations\"].shape[0]):\n",
    "    \n",
    "    # Loop over dimension 2 of simulated review timeseries (Products)\n",
    "    for e in range(experiment_2_data[\"simulations\"].shape[1]):\n",
    "        \n",
    "        augmented_timeseries[i][e] = augment_timeseries(experiment_2_data[\"simulations\"][i][e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2c6d301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of array of augmented time series: (12, 1600)\n",
      "Shape of array of original simulation time series: (12, 1600)\n"
     ]
    }
   ],
   "source": [
    "# Shape sanity check\n",
    "\n",
    "print(f\"Shape of array of augmented time series: {augmented_timeseries.shape}\")\n",
    "\n",
    "print(f\"Shape of array of original simulation time series: {experiment_2_data['simulations'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79c1123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute original simulation time series with augmented time series\n",
    "\n",
    "experiment_2_data[\"simulations\"] = augmented_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e0932d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store experiment 2 data as .pkl\n",
    "\n",
    "with open('inference_experiment_2_data.pkl', 'wb') as file:\n",
    "    pickle.dump(experiment_2_data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
